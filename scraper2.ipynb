{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:56<00:00,  1.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         Job Title Experience Level  \\\n",
      "0                     Data Science        3 - 5 yrs   \n",
      "1                     Data Science        4 - 6 yrs   \n",
      "2                     Data Science        3 - 6 yrs   \n",
      "3  Data Science Internship in Pune        0 - 1 yrs   \n",
      "4        Data Science Manager Jobs        2 - 7 yrs   \n",
      "\n",
      "                                 Company  \\\n",
      "0                     tcg digital soluti   \n",
      "1                             innefu lab   \n",
      "2                                    bpr   \n",
      "3                    Maxgen Technologies   \n",
      "4  SKYWALK VISA IMMIGRATION SERVICES LLP   \n",
      "\n",
      "                                     Skills Required              Salary  \\\n",
      "0  data analytics  ,  functional analysis  ,  pre...       Not Available   \n",
      "1  procedures  ,  data collection  ,   Commercial...       Not Available   \n",
      "2  hive  ,  algorithms  ,  authoring  ,  data min...       Not Available   \n",
      "3           internship  ,  data science  ,  power bi       Not Available   \n",
      "4  Data Science  ,  Data Scientist  ,  statistica...  Rs 3.10 - 99.00 La   \n",
      "\n",
      "                                         Description  \\\n",
      "0  ducation Masters / Bachelors degree in Compute...   \n",
      "1  ocation: DelhiDescription:4-6 YearsUsing machi...   \n",
      "2  evelop and plan required analytic projects in ...   \n",
      "3  axgen Technologies pvt ltd offering an interns...   \n",
      "4  all or Whatsapp to check your eligibilityAman ...   \n",
      "\n",
      "                                            Job Link  \\\n",
      "0  https://www.timesjobs.com/job-detail/data-scie...   \n",
      "1  https://www.timesjobs.com/job-detail/data-scie...   \n",
      "2  https://www.timesjobs.com/job-detail/data-scie...   \n",
      "3  https://www.timesjobs.com/job-detail/data-scie...   \n",
      "4  https://www.timesjobs.com/job-detail/data-scie...   \n",
      "\n",
      "                                            Location          Posted Date  \n",
      "0                                            Kolkata  Posted few days ago  \n",
      "1                                  Delhi,  Delhi/NCR  Posted few days ago  \n",
      "2                                             Mumbai  Posted few days ago  \n",
      "3                         Pune,  Jalgaon,  Kolhapur,    Posted 3 days ago  \n",
      "4  \\nAustralia,  Canada,  Germany,  Netherlands, ...  Posted few days ago  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 750 entries, 0 to 749\n",
      "Data columns (total 9 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Job Title         750 non-null    object\n",
      " 1   Experience Level  750 non-null    object\n",
      " 2   Company           750 non-null    object\n",
      " 3   Skills Required   750 non-null    object\n",
      " 4   Salary            750 non-null    object\n",
      " 5   Description       750 non-null    object\n",
      " 6   Job Link          750 non-null    object\n",
      " 7   Location          750 non-null    object\n",
      " 8   Posted Date       750 non-null    object\n",
      "dtypes: object(9)\n",
      "memory usage: 52.9+ KB\n",
      "None\n",
      "Job Title >>> Unique values count: 453\n",
      "Experience Level >>> Unique values count: 68\n",
      "Company >>> Unique values count: 129\n",
      "Skills Required >>> Unique values count: 531\n",
      "Salary >>> Unique values count: 90\n",
      "Description >>> Unique values count: 510\n",
      "Job Link >>> Unique values count: 749\n",
      "Location >>> Unique values count: 328\n",
      "Posted Date >>> Unique values count: 12\n",
      "Experience Level\n",
      "0 - 3 yrs      175\n",
      "0 - 1 yrs       90\n",
      "5 - 8 yrs       44\n",
      "2 - 5 yrs       31\n",
      "3 - 5 yrs       28\n",
      "              ... \n",
      "5 - 15 yrs       1\n",
      "3 - 10 yrs       1\n",
      "2 - 10 yrs       1\n",
      "4 - 12 yrs       1\n",
      "15 - 20 yrs      1\n",
      "Name: count, Length: 68, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Scraping job listings from TimesJobs for the first 30 pages\n",
    "from tqdm import tqdm\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize lists to store job data\n",
    "job_titles = []\n",
    "experience_levels = []\n",
    "companies = []\n",
    "skills_required = []\n",
    "descriptions = []\n",
    "salaries = []\n",
    "locations = []\n",
    "job_links = []\n",
    "posting_dates = []\n",
    "\n",
    "# Iterate over the first 30 pages of job listings\n",
    "for page in tqdm(range(1, 31)):\n",
    "    # Fetch the HTML content for the current page\n",
    "    url = f\"https://www.timesjobs.com/candidate/job-search.html?from=submit&luceneResultSize=25&txtKeywords=data%20science&postWeek=60&searchType=personalizedSearch&actualTxtKeywords=Data%20Science&searchBy=0&rdoOperator=OR&pDate=I&sequence={page}&startPage=1\"\n",
    "    response = requests.get(url)\n",
    "    html_content = response.text\n",
    "    \n",
    "    # Parse the HTML content using BeautifulSoup\n",
    "    soup = BeautifulSoup(html_content, \"html.parser\")\n",
    "    \n",
    "    # Find all job postings on the page\n",
    "    job_postings = soup.find_all(\"li\", class_=\"clearfix job-bx wht-shd-bx\")\n",
    "    \n",
    "    for posting in job_postings:\n",
    "        \n",
    "        # from each \n",
    "        job_title = posting.find(\"h2\").text.strip()\n",
    "        experience = posting.find(\"ul\", class_=\"top-jd-dtl clearfix\").li.text[11:]\n",
    "        company = posting.find(\"h3\", class_=\"joblist-comp-name\").text.strip()[:-11]\n",
    "        skills = posting.find(\"span\", class_=\"srp-skills\").text.strip()\n",
    "        description = posting.find(\"ul\", class_=\"list-job-dtl clearfix\").li.text\n",
    "        salary = posting.find(\"ul\", class_=\"top-jd-dtl clearfix\").text.strip()[20:]\n",
    "        posted_date = posting.find(\"span\", class_=\"sim-posted\").text.strip()\n",
    "        job_link = posting.header.h2.a[\"href\"]\n",
    "        \n",
    "        # Append extracted details to lists\n",
    "        job_titles.append(job_title)\n",
    "        experience_levels.append(experience.strip())\n",
    "        companies.append(company.strip())\n",
    "        skills_required.append(skills.strip())\n",
    "        descriptions.append(description.strip()[18:])\n",
    "        \n",
    "        # Extract and clean salary information\n",
    "        if \"₹Rs\" in salary:\n",
    "            salaries.append(salary[2:20])\n",
    "            locations.append(salary[40:])\n",
    "        else:\n",
    "            salaries.append(\"Not Available\")\n",
    "            locations.append(salary[14:40])\n",
    "        \n",
    "        job_links.append(job_link.strip())\n",
    "        posting_dates.append(posted_date)\n",
    "    \n",
    "    # into a df\n",
    "    job_data = pd.DataFrame({\n",
    "        \"Job Title\": job_titles,\n",
    "        \"Experience Level\": experience_levels,\n",
    "        \"Company\": companies,\n",
    "        \"Skills Required\": skills_required,\n",
    "        \"Salary\": salaries,\n",
    "        \"Description\": descriptions,\n",
    "        \"Job Link\": job_links,\n",
    "        \"Location\": locations,\n",
    "        \"Posted Date\": posting_dates\n",
    "    })\n",
    "    \n",
    "    # Save the DataFrame to a CSV file\n",
    "    job_data.to_csv(\"job_listings.csv\", index=False)\n",
    "\n",
    "# Display the first few rows and summary of the DataFrame\n",
    "print(job_data.head())\n",
    "print(job_data.info())\n",
    "\n",
    "# Print unique values count for each column\n",
    "for column in job_data.columns:\n",
    "    print(f\"{column} >>> Unique values count: {job_data[column].nunique()}\")\n",
    "\n",
    "# Print count of different experience levels\n",
    "experience_counts = job_data[\"Experience Level\"].value_counts()\n",
    "print(experience_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "job_titles = []\n",
    "experience_levels = []\n",
    "companies = []\n",
    "skills_required = []\n",
    "descriptions = []\n",
    "salaries = []\n",
    "locations = []\n",
    "job_links = []\n",
    "posting_dates = []\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
